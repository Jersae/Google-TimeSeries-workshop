{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSSD - N-Beats - TF Basic Setup.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jersae/Google-TimeSeries-workshop/blob/main/TSSD_N_Beats_TF_Basic_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do2dcLbRKRee"
      },
      "source": [
        "## N-Beats\n",
        "\n",
        "Model Implementation - https://github.com/philipperemy/n-beats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2z2G_dTyqia"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Subtract, Add, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj8_6UPJ3zkm",
        "outputId": "5e622211-486e-49e9-9fb6-c9cf7512b71d"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5vshlD4yqui"
      },
      "source": [
        "class NBeatsNet:\n",
        "    GENERIC_BLOCK = 'generic'\n",
        "    TREND_BLOCK = 'trend'\n",
        "    SEASONALITY_BLOCK = 'seasonality'\n",
        "\n",
        "    _BACKCAST = 'backcast'\n",
        "    _FORECAST = 'forecast'\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim=1,\n",
        "                 exo_dim=0,\n",
        "                 backcast_length=10,\n",
        "                 forecast_length=2,\n",
        "                 stack_types=(TREND_BLOCK, SEASONALITY_BLOCK),\n",
        "                 nb_blocks_per_stack=3,\n",
        "                 thetas_dim=(4, 8),\n",
        "                 share_weights_in_stack=False,\n",
        "                 hidden_layer_units=256,\n",
        "                 nb_harmonics=None):\n",
        "\n",
        "        self.stack_types = stack_types\n",
        "        self.nb_blocks_per_stack = nb_blocks_per_stack\n",
        "        self.thetas_dim = thetas_dim\n",
        "        self.units = hidden_layer_units\n",
        "        self.share_weights_in_stack = share_weights_in_stack\n",
        "        self.backcast_length = backcast_length\n",
        "        self.forecast_length = forecast_length\n",
        "        self.input_dim = input_dim\n",
        "        self.exo_dim = exo_dim\n",
        "        self.input_shape = (self.backcast_length, self.input_dim)\n",
        "        self.exo_shape = (self.backcast_length, self.exo_dim)\n",
        "        self.output_shape = (self.forecast_length, self.input_dim)\n",
        "        self.weights = {}\n",
        "        self.nb_harmonics = nb_harmonics\n",
        "        assert len(self.stack_types) == len(self.thetas_dim)\n",
        "\n",
        "        x = Input(shape=self.input_shape, name='input_variable')\n",
        "        x_ = {}\n",
        "        for k in range(self.input_dim):\n",
        "            x_[k] = Lambda(lambda z: z[..., k])(x)\n",
        "        e_ = {}\n",
        "        if self.has_exog():\n",
        "            e = Input(shape=self.exo_shape, name='exos_variables')\n",
        "            for k in range(self.exo_dim):\n",
        "                e_[k] = Lambda(lambda z: z[..., k])(e)\n",
        "        else:\n",
        "            e = None\n",
        "        y_ = {}\n",
        "\n",
        "        for stack_id in range(len(self.stack_types)):\n",
        "            stack_type = self.stack_types[stack_id]\n",
        "            nb_poly = self.thetas_dim[stack_id]\n",
        "            for block_id in range(self.nb_blocks_per_stack):\n",
        "                backcast, forecast = self.create_block(x_, e_, stack_id, block_id, stack_type, nb_poly)\n",
        "                for k in range(self.input_dim):\n",
        "                    x_[k] = Subtract()([x_[k], backcast[k]])\n",
        "                    if stack_id == 0 and block_id == 0:\n",
        "                        y_[k] = forecast[k]\n",
        "                    else:\n",
        "                        y_[k] = Add()([y_[k], forecast[k]])\n",
        "\n",
        "        for k in range(self.input_dim):\n",
        "            y_[k] = Reshape(target_shape=(self.forecast_length, 1))(y_[k])\n",
        "            x_[k] = Reshape(target_shape=(self.backcast_length, 1))(x_[k])\n",
        "        if self.input_dim > 1:\n",
        "            y_ = Concatenate()([y_[ll] for ll in range(self.input_dim)])\n",
        "            x_ = Concatenate()([x_[ll] for ll in range(self.input_dim)])\n",
        "        else:\n",
        "            y_ = y_[0]\n",
        "            x_ = x_[0]\n",
        "\n",
        "        if self.has_exog():\n",
        "            n_beats_forecast = Model([x, e], y_, name=self._FORECAST)\n",
        "            n_beats_backcast = Model([x, e], x_, name=self._BACKCAST)\n",
        "        else:\n",
        "            n_beats_forecast = Model(x, y_, name=self._FORECAST)\n",
        "            n_beats_backcast = Model(x, x_, name=self._BACKCAST)\n",
        "\n",
        "        self.models = {model.name: model for model in [n_beats_backcast, n_beats_forecast]}\n",
        "        self.cast_type = self._FORECAST\n",
        "\n",
        "    def has_exog(self):\n",
        "        # exo/exog is short for 'exogenous variable', i.e. any input\n",
        "        # features other than the target time-series itself.\n",
        "        return self.exo_dim > 0\n",
        "\n",
        "    @staticmethod\n",
        "    def load(filepath, custom_objects=None, compile=True):\n",
        "        from tensorflow.keras.models import load_model\n",
        "        return load_model(filepath, custom_objects, compile)\n",
        "\n",
        "    def _r(self, layer_with_weights, stack_id):\n",
        "        # mechanism to restore weights when block share the same weights.\n",
        "        # only useful when share_weights_in_stack=True.\n",
        "        if self.share_weights_in_stack:\n",
        "            layer_name = layer_with_weights.name.split('/')[-1]\n",
        "            try:\n",
        "                reused_weights = self.weights[stack_id][layer_name]\n",
        "                return reused_weights\n",
        "            except KeyError:\n",
        "                pass\n",
        "            if stack_id not in self.weights:\n",
        "                self.weights[stack_id] = {}\n",
        "            self.weights[stack_id][layer_name] = layer_with_weights\n",
        "        return layer_with_weights\n",
        "\n",
        "    def create_block(self, x, e, stack_id, block_id, stack_type, nb_poly):\n",
        "        # register weights (useful when share_weights_in_stack=True)\n",
        "        def reg(layer):\n",
        "            return self._r(layer, stack_id)\n",
        "\n",
        "        # update name (useful when share_weights_in_stack=True)\n",
        "        def n(layer_name):\n",
        "            return '/'.join([str(stack_id), str(block_id), stack_type, layer_name])\n",
        "\n",
        "        backcast_ = {}\n",
        "        forecast_ = {}\n",
        "        d1 = reg(Dense(self.units, activation='relu', name=n('d1')))\n",
        "        d2 = reg(Dense(self.units, activation='relu', name=n('d2')))\n",
        "        d3 = reg(Dense(self.units, activation='relu', name=n('d3')))\n",
        "        d4 = reg(Dense(self.units, activation='relu', name=n('d4')))\n",
        "        if stack_type == 'generic':\n",
        "            theta_b = reg(Dense(nb_poly, activation='linear', use_bias=False, name=n('theta_b')))\n",
        "            theta_f = reg(Dense(nb_poly, activation='linear', use_bias=False, name=n('theta_f')))\n",
        "            backcast = reg(Dense(self.backcast_length, activation='linear', name=n('backcast')))\n",
        "            forecast = reg(Dense(self.forecast_length, activation='linear', name=n('forecast')))\n",
        "        elif stack_type == 'trend':\n",
        "            theta_f = theta_b = reg(Dense(nb_poly, activation='linear', use_bias=False, name=n('theta_f_b')))\n",
        "            backcast = Lambda(trend_model, arguments={'is_forecast': False, 'backcast_length': self.backcast_length,\n",
        "                                                      'forecast_length': self.forecast_length})\n",
        "            forecast = Lambda(trend_model, arguments={'is_forecast': True, 'backcast_length': self.backcast_length,\n",
        "                                                      'forecast_length': self.forecast_length})\n",
        "        else:  # 'seasonality'\n",
        "            if self.nb_harmonics:\n",
        "                theta_b = reg(Dense(self.nb_harmonics, activation='linear', use_bias=False, name=n('theta_b')))\n",
        "            else:\n",
        "                theta_b = reg(Dense(self.forecast_length, activation='linear', use_bias=False, name=n('theta_b')))\n",
        "            theta_f = reg(Dense(self.forecast_length, activation='linear', use_bias=False, name=n('theta_f')))\n",
        "            backcast = Lambda(seasonality_model,\n",
        "                              arguments={'is_forecast': False, 'backcast_length': self.backcast_length,\n",
        "                                         'forecast_length': self.forecast_length})\n",
        "            forecast = Lambda(seasonality_model,\n",
        "                              arguments={'is_forecast': True, 'backcast_length': self.backcast_length,\n",
        "                                         'forecast_length': self.forecast_length})\n",
        "        for k in range(self.input_dim):\n",
        "            if self.has_exog():\n",
        "                d0 = Concatenate()([x[k]] + [e[ll] for ll in range(self.exo_dim)])\n",
        "            else:\n",
        "                d0 = x[k]\n",
        "            d1_ = d1(d0)\n",
        "            d2_ = d2(d1_)\n",
        "            d3_ = d3(d2_)\n",
        "            d4_ = d4(d3_)\n",
        "            theta_f_ = theta_f(d4_)\n",
        "            theta_b_ = theta_b(d4_)\n",
        "            backcast_[k] = backcast(theta_b_)\n",
        "            forecast_[k] = forecast(theta_f_)\n",
        "\n",
        "        return backcast_, forecast_\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        # https://github.com/faif/python-patterns\n",
        "        # model.predict() instead of model.n_beats.predict()\n",
        "        # same for fit(), train_on_batch()...\n",
        "        attr = getattr(self.models[self._FORECAST], name)\n",
        "\n",
        "        if not callable(attr):\n",
        "            return attr\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            cast_type = self._FORECAST\n",
        "            if attr.__name__ == 'predict' and 'return_backcast' in kwargs and kwargs['return_backcast']:\n",
        "                del kwargs['return_backcast']\n",
        "                cast_type = self._BACKCAST\n",
        "            return getattr(self.models[cast_type], attr.__name__)(*args, **kwargs)\n",
        "\n",
        "        return wrapper\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDCBOewcylRA"
      },
      "source": [
        "# utils\n",
        "\n",
        "def linear_space(backcast_length, forecast_length, is_forecast=True):\n",
        "    ls = K.arange(-float(backcast_length), float(forecast_length), 1) / forecast_length\n",
        "    return ls[backcast_length:] if is_forecast else ls[:backcast_length]\n",
        "\n",
        "\n",
        "def seasonality_model(thetas, backcast_length, forecast_length, is_forecast):\n",
        "    p = thetas.get_shape().as_list()[-1]\n",
        "    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)\n",
        "    t = linear_space(backcast_length, forecast_length, is_forecast=is_forecast)\n",
        "    s1 = K.stack([K.cos(2 * np.pi * i * t) for i in range(p1)])\n",
        "    s2 = K.stack([K.sin(2 * np.pi * i * t) for i in range(p2)])\n",
        "    if p == 1:\n",
        "        s = s2\n",
        "    else:\n",
        "        s = K.concatenate([s1, s2], axis=0)\n",
        "    s = K.cast(s, np.float32)\n",
        "    return K.dot(thetas, s)\n",
        "\n",
        "\n",
        "def trend_model(thetas, backcast_length, forecast_length, is_forecast):\n",
        "    p = thetas.shape[-1]\n",
        "    t = linear_space(backcast_length, forecast_length, is_forecast=is_forecast)\n",
        "    t = K.transpose(K.stack([t ** i for i in range(p)]))\n",
        "    t = K.cast(t, np.float32)\n",
        "    return K.dot(thetas, K.transpose(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wGqCrkLyqxC"
      },
      "source": [
        "# Using the model\n",
        "# https://keras.io/layers/recurrent/\n",
        "num_samples, time_steps, input_dim, output_dim = 50_000, 10, 1, 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f-0qwS-yq5G"
      },
      "source": [
        "# Definition of the model.\n",
        "model = NBeatsNet(backcast_length=time_steps, \n",
        "                          forecast_length=output_dim,\n",
        "                          stack_types=(NBeatsNet.GENERIC_BLOCK, NBeatsNet.GENERIC_BLOCK),\n",
        "                          nb_blocks_per_stack=4, \n",
        "                          thetas_dim=(4, 4), \n",
        "                          share_weights_in_stack=True,\n",
        "                          hidden_layer_units=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGgp5RQ3wHeV"
      },
      "source": [
        "# Definition of the objective function and the optimizer.\n",
        "model.compile(loss='mae', \n",
        "              optimizer='adam',\n",
        "              metrics=['mae','mape']\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi_ObIsiwL9o",
        "outputId": "b330d80e-b008-4d00-e27f-cea4fb14fa55"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"forecast\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_variable (InputLayer)     [(None, 10, 1)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 10)           0           input_variable[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/d1 (Dense)          (None, 64)           704         lambda[0][0]                     \n",
            "                                                                 subtract[0][0]                   \n",
            "                                                                 subtract_1[0][0]                 \n",
            "                                                                 subtract_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/d2 (Dense)          (None, 64)           4160        0/0/generic/d1[0][0]             \n",
            "                                                                 0/0/generic/d1[1][0]             \n",
            "                                                                 0/0/generic/d1[2][0]             \n",
            "                                                                 0/0/generic/d1[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/d3 (Dense)          (None, 64)           4160        0/0/generic/d2[0][0]             \n",
            "                                                                 0/0/generic/d2[1][0]             \n",
            "                                                                 0/0/generic/d2[2][0]             \n",
            "                                                                 0/0/generic/d2[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/d4 (Dense)          (None, 64)           4160        0/0/generic/d3[0][0]             \n",
            "                                                                 0/0/generic/d3[1][0]             \n",
            "                                                                 0/0/generic/d3[2][0]             \n",
            "                                                                 0/0/generic/d3[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/theta_b (Dense)     (None, 4)            256         0/0/generic/d4[0][0]             \n",
            "                                                                 0/0/generic/d4[1][0]             \n",
            "                                                                 0/0/generic/d4[2][0]             \n",
            "                                                                 0/0/generic/d4[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/backcast (Dense)    (None, 10)           50          0/0/generic/theta_b[0][0]        \n",
            "                                                                 0/0/generic/theta_b[1][0]        \n",
            "                                                                 0/0/generic/theta_b[2][0]        \n",
            "                                                                 0/0/generic/theta_b[3][0]        \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 10)           0           lambda[0][0]                     \n",
            "                                                                 0/0/generic/backcast[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 10)           0           subtract[0][0]                   \n",
            "                                                                 0/0/generic/backcast[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "subtract_2 (Subtract)           (None, 10)           0           subtract_1[0][0]                 \n",
            "                                                                 0/0/generic/backcast[2][0]       \n",
            "__________________________________________________________________________________________________\n",
            "subtract_3 (Subtract)           (None, 10)           0           subtract_2[0][0]                 \n",
            "                                                                 0/0/generic/backcast[3][0]       \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/d1 (Dense)          (None, 64)           704         subtract_3[0][0]                 \n",
            "                                                                 subtract_4[0][0]                 \n",
            "                                                                 subtract_5[0][0]                 \n",
            "                                                                 subtract_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/d2 (Dense)          (None, 64)           4160        1/0/generic/d1[0][0]             \n",
            "                                                                 1/0/generic/d1[1][0]             \n",
            "                                                                 1/0/generic/d1[2][0]             \n",
            "                                                                 1/0/generic/d1[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/d3 (Dense)          (None, 64)           4160        1/0/generic/d2[0][0]             \n",
            "                                                                 1/0/generic/d2[1][0]             \n",
            "                                                                 1/0/generic/d2[2][0]             \n",
            "                                                                 1/0/generic/d2[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/d4 (Dense)          (None, 64)           4160        1/0/generic/d3[0][0]             \n",
            "                                                                 1/0/generic/d3[1][0]             \n",
            "                                                                 1/0/generic/d3[2][0]             \n",
            "                                                                 1/0/generic/d3[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/theta_b (Dense)     (None, 4)            256         1/0/generic/d4[0][0]             \n",
            "                                                                 1/0/generic/d4[1][0]             \n",
            "                                                                 1/0/generic/d4[2][0]             \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/backcast (Dense)    (None, 10)           50          1/0/generic/theta_b[0][0]        \n",
            "                                                                 1/0/generic/theta_b[1][0]        \n",
            "                                                                 1/0/generic/theta_b[2][0]        \n",
            "__________________________________________________________________________________________________\n",
            "subtract_4 (Subtract)           (None, 10)           0           subtract_3[0][0]                 \n",
            "                                                                 1/0/generic/backcast[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "subtract_5 (Subtract)           (None, 10)           0           subtract_4[0][0]                 \n",
            "                                                                 1/0/generic/backcast[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/theta_f (Dense)     (None, 4)            256         0/0/generic/d4[0][0]             \n",
            "                                                                 0/0/generic/d4[1][0]             \n",
            "                                                                 0/0/generic/d4[2][0]             \n",
            "                                                                 0/0/generic/d4[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "0/0/generic/forecast (Dense)    (None, 1)            5           0/0/generic/theta_f[0][0]        \n",
            "                                                                 0/0/generic/theta_f[1][0]        \n",
            "                                                                 0/0/generic/theta_f[2][0]        \n",
            "                                                                 0/0/generic/theta_f[3][0]        \n",
            "__________________________________________________________________________________________________\n",
            "subtract_6 (Subtract)           (None, 10)           0           subtract_5[0][0]                 \n",
            "                                                                 1/0/generic/backcast[2][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 1)            0           0/0/generic/forecast[0][0]       \n",
            "                                                                 0/0/generic/forecast[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1)            0           add[0][0]                        \n",
            "                                                                 0/0/generic/forecast[2][0]       \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/theta_f (Dense)     (None, 4)            256         1/0/generic/d4[0][0]             \n",
            "                                                                 1/0/generic/d4[1][0]             \n",
            "                                                                 1/0/generic/d4[2][0]             \n",
            "                                                                 1/0/generic/d4[3][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1)            0           add_1[0][0]                      \n",
            "                                                                 0/0/generic/forecast[3][0]       \n",
            "__________________________________________________________________________________________________\n",
            "1/0/generic/forecast (Dense)    (None, 1)            5           1/0/generic/theta_f[0][0]        \n",
            "                                                                 1/0/generic/theta_f[1][0]        \n",
            "                                                                 1/0/generic/theta_f[2][0]        \n",
            "                                                                 1/0/generic/theta_f[3][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 1)            0           add_2[0][0]                      \n",
            "                                                                 1/0/generic/forecast[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 1)            0           add_3[0][0]                      \n",
            "                                                                 1/0/generic/forecast[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 1)            0           add_4[0][0]                      \n",
            "                                                                 1/0/generic/forecast[2][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 1)            0           add_5[0][0]                      \n",
            "                                                                 1/0/generic/forecast[3][0]       \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 1)         0           add_6[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 27,502\n",
            "Trainable params: 27,502\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hc9wT191YtX"
      },
      "source": [
        "# Definition of the data. The problem to solve is to find f such as | f(x) - y | -> 0.\n",
        "    # where f = np.mean.\n",
        "x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
        "y = np.mean(x, axis=1, keepdims=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcQbiSxT1lNh",
        "outputId": "75d3c92c-09e5-4b20-965c-45edbafe51fd"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 10, 1), (50000, 1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I78yY-eJ1nm5"
      },
      "source": [
        "# Split data into training and testing datasets.\n",
        "c = num_samples // 10\n",
        "x_train, y_train, x_test, y_test = x[c:], y[c:], x[:c], y[:c]\n",
        "test_size = len(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhSxgoZk1t6W",
        "outputId": "7bbeec95-1443-454b-93ec-b90e2df2b3f4"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((45000, 10, 1), (45000, 1, 1), (5000, 10, 1), (5000, 1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFrVzpC2rNe"
      },
      "source": [
        "# callback for checkpointing best model\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint( './best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NefvtQPq11_d",
        "outputId": "5ae5dab3-57fd-4752-d8a2-05a3193e0503"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "                validation_data=(x_test, y_test), \n",
        "                epochs=50, \n",
        "                batch_size=128,\n",
        "                callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 5s 9ms/step - loss: 0.0458 - mae: 0.0458 - mape: 9.3793 - val_loss: 0.0093 - val_mae: 0.0093 - val_mape: 1.9390\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00928, saving model to ./best_model.h5\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0107 - mae: 0.0107 - mape: 2.1860 - val_loss: 0.0150 - val_mae: 0.0150 - val_mape: 3.0570\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00928\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0082 - mae: 0.0082 - mape: 1.6870 - val_loss: 0.0042 - val_mae: 0.0042 - val_mape: 0.8743\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00928 to 0.00420, saving model to ./best_model.h5\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0072 - mae: 0.0072 - mape: 1.4618 - val_loss: 0.0045 - val_mae: 0.0045 - val_mape: 0.9291\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00420\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0067 - mae: 0.0067 - mape: 1.3617 - val_loss: 0.0089 - val_mae: 0.0089 - val_mape: 1.8478\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00420\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0055 - mae: 0.0055 - mape: 1.1256 - val_loss: 0.0159 - val_mae: 0.0159 - val_mape: 3.2610\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00420\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0059 - mae: 0.0059 - mape: 1.2126 - val_loss: 0.0055 - val_mae: 0.0055 - val_mape: 1.1571\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00420\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0051 - mae: 0.0051 - mape: 1.0508 - val_loss: 0.0096 - val_mae: 0.0096 - val_mape: 1.9648\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00420\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0051 - mae: 0.0051 - mape: 1.0339 - val_loss: 0.0018 - val_mae: 0.0018 - val_mape: 0.3704\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00420 to 0.00176, saving model to ./best_model.h5\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0045 - mae: 0.0045 - mape: 0.9272 - val_loss: 0.0054 - val_mae: 0.0054 - val_mape: 1.0856\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00176\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0037 - mae: 0.0037 - mape: 0.7636 - val_loss: 0.0036 - val_mae: 0.0036 - val_mape: 0.7379\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00176\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0047 - mae: 0.0047 - mape: 0.9490 - val_loss: 0.0047 - val_mae: 0.0047 - val_mape: 0.9748\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00176\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0047 - mae: 0.0047 - mape: 0.9488 - val_loss: 0.0045 - val_mae: 0.0045 - val_mape: 0.9143\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00176\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0039 - mae: 0.0039 - mape: 0.7934 - val_loss: 0.0105 - val_mae: 0.0105 - val_mape: 2.1031\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00176\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0049 - mae: 0.0049 - mape: 0.9959 - val_loss: 0.0024 - val_mae: 0.0024 - val_mape: 0.4999\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00176\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0034 - mae: 0.0034 - mape: 0.6946 - val_loss: 0.0029 - val_mae: 0.0029 - val_mape: 0.5900\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00176\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0030 - mae: 0.0030 - mape: 0.6075 - val_loss: 0.0015 - val_mae: 0.0015 - val_mape: 0.3143\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00176 to 0.00150, saving model to ./best_model.h5\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0031 - mae: 0.0031 - mape: 0.6245 - val_loss: 0.0025 - val_mae: 0.0025 - val_mape: 0.5035\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00150\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0036 - mae: 0.0036 - mape: 0.7236 - val_loss: 0.0020 - val_mae: 0.0020 - val_mape: 0.4326\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00150\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0023 - mae: 0.0023 - mape: 0.4810 - val_loss: 0.0013 - val_mae: 0.0013 - val_mape: 0.2774\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00150 to 0.00135, saving model to ./best_model.h5\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0029 - mae: 0.0029 - mape: 0.5883 - val_loss: 0.0064 - val_mae: 0.0064 - val_mape: 1.2871\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00135\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0035 - mae: 0.0035 - mape: 0.7144 - val_loss: 0.0020 - val_mae: 0.0020 - val_mape: 0.4105\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00135\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0035 - mae: 0.0035 - mape: 0.7065 - val_loss: 0.0036 - val_mae: 0.0036 - val_mape: 0.7143\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00135\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0027 - mae: 0.0027 - mape: 0.5593 - val_loss: 0.0014 - val_mae: 0.0014 - val_mape: 0.3091\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00135\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0024 - mae: 0.0024 - mape: 0.4799 - val_loss: 0.0024 - val_mae: 0.0024 - val_mape: 0.4802\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00135\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0034 - mae: 0.0034 - mape: 0.6991 - val_loss: 0.0026 - val_mae: 0.0026 - val_mape: 0.5357\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00135\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0025 - mae: 0.0025 - mape: 0.5182 - val_loss: 0.0011 - val_mae: 0.0011 - val_mape: 0.2275\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00135 to 0.00111, saving model to ./best_model.h5\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0020 - mae: 0.0020 - mape: 0.4105 - val_loss: 0.0024 - val_mae: 0.0024 - val_mape: 0.5024\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00111\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0043 - mae: 0.0043 - mape: 0.8793 - val_loss: 0.0038 - val_mae: 0.0038 - val_mape: 0.7722\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00111\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0030 - mae: 0.0030 - mape: 0.6114 - val_loss: 0.0011 - val_mae: 0.0011 - val_mape: 0.2260\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00111 to 0.00108, saving model to ./best_model.h5\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0017 - mae: 0.0017 - mape: 0.3394 - val_loss: 0.0053 - val_mae: 0.0053 - val_mape: 1.0934\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00108\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0028 - mae: 0.0028 - mape: 0.5748 - val_loss: 0.0024 - val_mae: 0.0024 - val_mape: 0.4797\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00108\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0021 - mae: 0.0021 - mape: 0.4332 - val_loss: 0.0055 - val_mae: 0.0055 - val_mape: 1.0973\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00108\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0032 - mae: 0.0032 - mape: 0.6386 - val_loss: 0.0024 - val_mae: 0.0024 - val_mape: 0.4988\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00108\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0021 - mae: 0.0021 - mape: 0.4295 - val_loss: 6.9490e-04 - val_mae: 6.9490e-04 - val_mape: 0.1482\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00108 to 0.00069, saving model to ./best_model.h5\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0022 - mae: 0.0022 - mape: 0.4431 - val_loss: 0.0064 - val_mae: 0.0064 - val_mape: 1.2951\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00069\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0031 - mae: 0.0031 - mape: 0.6193 - val_loss: 0.0012 - val_mae: 0.0012 - val_mape: 0.2431\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00069\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0020 - mae: 0.0020 - mape: 0.4071 - val_loss: 0.0049 - val_mae: 0.0049 - val_mape: 0.9956\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00069\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0026 - mae: 0.0026 - mape: 0.5386 - val_loss: 0.0033 - val_mae: 0.0033 - val_mape: 0.7154\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00069\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0030 - mae: 0.0030 - mape: 0.6139 - val_loss: 0.0010 - val_mae: 0.0010 - val_mape: 0.2206\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00069\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0013 - mae: 0.0013 - mape: 0.2725 - val_loss: 6.1331e-04 - val_mae: 6.1331e-04 - val_mape: 0.1300\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00069 to 0.00061, saving model to ./best_model.h5\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0017 - mae: 0.0017 - mape: 0.3569 - val_loss: 0.0029 - val_mae: 0.0029 - val_mape: 0.5728\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00061\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0018 - mae: 0.0018 - mape: 0.3587 - val_loss: 0.0012 - val_mae: 0.0012 - val_mape: 0.2525\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00061\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0019 - mae: 0.0019 - mape: 0.3912 - val_loss: 0.0027 - val_mae: 0.0027 - val_mape: 0.5392\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00061\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0028 - mae: 0.0028 - mape: 0.5588 - val_loss: 9.5723e-04 - val_mae: 9.5723e-04 - val_mape: 0.2059\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00061\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0022 - mae: 0.0022 - mape: 0.4556 - val_loss: 6.1546e-04 - val_mae: 6.1546e-04 - val_mape: 0.1306\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00061\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0020 - mae: 0.0020 - mape: 0.4184 - val_loss: 0.0019 - val_mae: 0.0019 - val_mape: 0.3875\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00061\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0017 - mae: 0.0017 - mape: 0.3486 - val_loss: 0.0031 - val_mae: 0.0031 - val_mape: 0.6350\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00061\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0017 - mae: 0.0017 - mape: 0.3513 - val_loss: 8.8553e-04 - val_mae: 8.8553e-04 - val_mape: 0.1840\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00061\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0028 - mae: 0.0028 - mape: 0.5679 - val_loss: 0.0031 - val_mae: 0.0031 - val_mape: 0.5994\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f206d1706d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNOCYYUj181k",
        "outputId": "cec4dac8-88ac-4404-86b5-b665200a290a"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0067 - mape: 1.3935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0067247869446873665, 0.0067247869446873665, 1.3934729099273682]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p47Luu32lTR",
        "outputId": "e167fd6d-5413-4944-8e88-0f9d5143e283"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model.h5  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q27Namr4E1N",
        "outputId": "22f495ed-4ea4-442d-b58f-51034b3250ce"
      },
      "source": [
        "model = tf.keras.models.load_model('./best_model.h5')\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0021 - mape: 0.4219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00212465925142169, 0.00212465925142169, 0.4219164550304413]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "lLK65wVw4cjw",
        "outputId": "f918f9db-09cb-4993-dc6d-19fb8ed352e6"
      },
      "source": [
        "# Predict on the testing set (forecast).\n",
        "predictions_forecast = model.predict(x_test)\n",
        "\n",
        "# Predict on the testing set (backcast).\n",
        "predictions_backcast = model.predict(x_test, return_backcast=True)\n",
        "\n",
        "np.testing.assert_equal(predictions_forecast.shape, (test_size, model.forecast_length, output_dim))\n",
        "np.testing.assert_equal(predictions_backcast.shape, (test_size, model.backcast_length, output_dim))\n",
        "\n",
        "\n",
        "predictions_backcast.shape, predictions_forecast.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-28c7894fc162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Predict on the testing set (backcast).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions_backcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_backcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_forecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'return_backcast'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln533aBP51nD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}