{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chee Wee - CodeAlong TSSD - CC Fraud Imbalanced Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jersae/Google-TimeSeries-workshop/blob/main/Chee_Wee_CodeAlong_TSSD_CC_Fraud_Imbalanced_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvsAfdkF6TwE"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/fljaie1ajeze8vy/creditcard.csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9Hu-zqf6d0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf2a27a-af12-4df9-96f8-97f96912a3cb"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creditcard.csv              fraud_model_at_epoch_21.h5\n",
            "creditcard.csv.1            fraud_model_at_epoch_22.h5\n",
            "creditcard.csv.2            fraud_model_at_epoch_23.h5\n",
            "creditcard.csv.3            fraud_model_at_epoch_24.h5\n",
            "creditcard.csv.4            fraud_model_at_epoch_25.h5\n",
            "creditcard.csv.5            fraud_model_at_epoch_26.h5\n",
            "creditcard.csv.6            fraud_model_at_epoch_27.h5\n",
            "creditcard.csv.7            fraud_model_at_epoch_28.h5\n",
            "fraud_model_at_epoch_10.h5  fraud_model_at_epoch_29.h5\n",
            "fraud_model_at_epoch_11.h5  fraud_model_at_epoch_2.h5\n",
            "fraud_model_at_epoch_12.h5  fraud_model_at_epoch_30.h5\n",
            "fraud_model_at_epoch_13.h5  fraud_model_at_epoch_3.h5\n",
            "fraud_model_at_epoch_14.h5  fraud_model_at_epoch_4.h5\n",
            "fraud_model_at_epoch_15.h5  fraud_model_at_epoch_5.h5\n",
            "fraud_model_at_epoch_16.h5  fraud_model_at_epoch_6.h5\n",
            "fraud_model_at_epoch_17.h5  fraud_model_at_epoch_7.h5\n",
            "fraud_model_at_epoch_18.h5  fraud_model_at_epoch_8.h5\n",
            "fraud_model_at_epoch_19.h5  fraud_model_at_epoch_9.h5\n",
            "fraud_model_at_epoch_1.h5   \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "fraud_model_at_epoch_20.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceJahkPk6vt0"
      },
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZwfSask6wfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f68adbee-0567-4dbd-ce72-b5009e21ad94"
      },
      "source": [
        "df = pd.read_csv('./creditcard.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgotMfJl63XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806d9e9a-da49-4399-e6f8-b497bbcd26f3"
      },
      "source": [
        "labels = df.pop('Class')\n",
        "print(labels.value_counts())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvSLkIMsH7kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11210faa-a75f-4a56-e262-3ab98b21577d"
      },
      "source": [
        "features = df.values\n",
        "#cols = ['Time', 'V7', 'V8']\n",
        "\n",
        "#df[cols].values.tolist()\n",
        "\n",
        "features.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tik5jLrW8r-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cb4bc2-546d-485b-dde1-7699c4d66530"
      },
      "source": [
        "labels = labels.to_numpy().reshape(len(labels), 1)\n",
        "\n",
        "labels.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqSbzFprACt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d589b191-a021-4c6e-e920-3d02c8650cdd"
      },
      "source": [
        "# train test split\n",
        "split = int(len(features) * 0.8)\n",
        "\n",
        "x_train, y_train = features[:split], labels[:split]\n",
        "x_test, y_test = features[split:], labels[split:]\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((227845, 30), (56962, 30), (227845, 1), (56962, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbcq-hWdF5_w"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibHndbthErfi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5f98b541-c1ad-462b-e87a-e46bef8c26e8"
      },
      "source": [
        "# old fashioned way\n",
        "\"\"\"\n",
        "x_train_old = x_train\n",
        "mean = np.mean(x_train_old, axis = 0)\n",
        "x_train_old -+ mean\n",
        "std = np.std(x_train_old, axis=0)\n",
        "x_train_old /= std\n",
        "\n",
        "mean, std, x_train_old\n",
        "\"\"\"\n",
        "\n",
        "#use tf.keras.layers.experimental.preprocessing.Normalization\n",
        "#use adapt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx_train_old = x_train\\nmean = np.mean(x_train_old, axis = 0)\\nx_train_old -+ mean\\nstd = np.std(x_train_old, axis=0)\\nx_train_old /= std\\n\\nmean, std, x_train_old\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRS62waCJxFN",
        "outputId": "b37567dc-9928-46cc-e409-90085178d535"
      },
      "source": [
        "#new implementation (Seems like it is consisten with old)\n",
        "layer_tryout = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "layer_tryout.adapt(x_train)\n",
        "layer_tryout.mean, layer_tryout.variance, layer_tryout"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'mean:0' shape=(30,) dtype=float32, numpy=\n",
              " array([ 7.9042797e+04, -6.7180790e-02, -1.3512367e-02,  1.8250893e-01,\n",
              "         4.3790787e-02, -6.3728966e-02,  3.0536966e-02, -2.6842874e-02,\n",
              "         3.9854795e-03,  2.2204972e-03, -1.7066291e-03,  7.6276384e-02,\n",
              "        -4.4996548e-02,  1.6711891e-02,  3.2869250e-02,  4.9113471e-02,\n",
              "        -5.5079609e-03,  1.5156597e-02, -2.2870937e-02, -7.2854543e-03,\n",
              "         9.9472860e-03, -6.6195866e-03, -2.2912972e-02, -9.9146282e-03,\n",
              "         1.1059723e-03,  3.8057819e-02,  2.8380959e-03,  2.2927098e-04,\n",
              "         1.9619404e-03,  9.0824921e+01], dtype=float32)>,\n",
              " <tf.Variable 'variance:0' shape=(30,) dtype=float32, numpy=\n",
              " array([1.5607127e+09, 3.7771056e+00, 2.7487762e+00, 2.2213550e+00,\n",
              "        1.9917129e+00, 1.8854131e+00, 1.7461371e+00, 1.5085671e+00,\n",
              "        1.4631439e+00, 1.2620698e+00, 1.1966792e+00, 1.0681466e+00,\n",
              "        1.1148453e+00, 1.0395586e+00, 9.3261760e-01, 8.7219071e-01,\n",
              "        7.8433996e-01, 7.6417398e-01, 7.1028268e-01, 6.7243397e-01,\n",
              "        6.0689926e-01, 5.5425692e-01, 5.0217736e-01, 3.9758179e-01,\n",
              "        3.6721292e-01, 2.5784203e-01, 2.3687658e-01, 1.6036694e-01,\n",
              "        1.1164304e-01, 6.2751863e+04], dtype=float32)>,\n",
              " <tensorflow.python.keras.layers.preprocessing.normalization.Normalization at 0x7fd962527910>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIuJWpfAEit4"
      },
      "source": [
        "## Deal with weight imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ADi9WftEIj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8c0bb6-995a-47e9-83f7-2d212a2d52ec"
      },
      "source": [
        "counts = np.bincount(y_train[:,0])\n",
        "\n",
        "counts[1], 100*float(counts[1]/len(y_train))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(417, 0.18301915776075842)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdL0kNdzRfHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60167fc2-1be4-43be-b2db-dc217ae74ff1"
      },
      "source": [
        "company_weighting = 1.0\n",
        "\n",
        "weight_for_0 = 1.0/counts[0] * company_weighting\n",
        "weight_for_1 = 1.0/counts[1] * company_weighting\n",
        "\n",
        "print(\"fraud weighting \", weight_for_1, 'Normal', weight_for_0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fraud weighting  0.002398081534772182 Normal 4.3969959723516896e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN7N26e_Igp0"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh4whGfKIhqx"
      },
      "source": [
        "layer = tf.keras.layers.experimental.preprocessing.Normalization(name=\"normalisation\")\n",
        "layer.adapt(x_train)\n",
        "\n",
        "Inp = Input(shape=[30,1], name='Input')\n",
        "x = Flatten(name='Flatten_01')(Inp)\n",
        "x = layer(x)\n",
        "x = Dense(256, activation='relu', name='dense_01')(x)\n",
        "x = Dense(256, activation='relu', name='dense_02')(x)\n",
        "x = Dropout(0.3, name='Dropout_01')(x)\n",
        "x = Dense(256, activation='relu', name='dense_03')(x)\n",
        "x = Dropout(0.3, name='Dropout_02')(x)\n",
        "outputs = Dense(1, activation='sigmoid', name='output')(x)\n",
        "\n",
        "model = tf.keras.Model(Inp, outputs, name='CC_Fraud_model')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuyXMzOCJOra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82ee672-37ff-4653-89ca-7191d9dede9c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"CC_Fraud_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           [(None, 30, 1)]           0         \n",
            "_________________________________________________________________\n",
            "Flatten_01 (Flatten)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "normalisation (Normalization (None, 30)                61        \n",
            "_________________________________________________________________\n",
            "dense_01 (Dense)             (None, 256)               7936      \n",
            "_________________________________________________________________\n",
            "dense_02 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "Dropout_01 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_03 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "Dropout_02 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 139,838\n",
            "Trainable params: 139,777\n",
            "Non-trainable params: 61\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOpeSAB-J1Hu"
      },
      "source": [
        "metrics = [tf.keras.metrics.FalseNegatives(name='fn'), tf.keras.metrics.FalsePositives(name='fp'), tf.keras.metrics.TrueNegatives(name='tn'), tf.keras.metrics.TruePositives(name='tp'), tf.keras.metrics.Precision(name='Precision'), tf.keras.metrics.Recall(name='recall')]\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "\n",
        "class_weights = {0:weight_for_0, 1:weight_for_1}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJSeL9ksJ7rn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a90e35-01a1-4dca-8e6e-2b0bc243de65"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=2048, epochs=30, callbacks=callbacks, validation_data=(x_test , y_test), verbose=2, class_weight=class_weights)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 3s - loss: 2.3001e-06 - fn: 44.0000 - fp: 26629.0000 - tn: 200799.0000 - tp: 373.0000 - Precision: 0.0138 - recall: 0.8945 - val_loss: 0.1940 - val_fn: 6.0000 - val_fp: 2420.0000 - val_tn: 54467.0000 - val_tp: 69.0000 - val_Precision: 0.0277 - val_recall: 0.9200\n",
            "Epoch 2/30\n",
            "112/112 - 1s - loss: 1.5335e-06 - fn: 38.0000 - fp: 8289.0000 - tn: 219139.0000 - tp: 379.0000 - Precision: 0.0437 - recall: 0.9089 - val_loss: 0.0953 - val_fn: 8.0000 - val_fp: 1067.0000 - val_tn: 55820.0000 - val_tp: 67.0000 - val_Precision: 0.0591 - val_recall: 0.8933\n",
            "Epoch 3/30\n",
            "112/112 - 1s - loss: 1.1802e-06 - fn: 34.0000 - fp: 5808.0000 - tn: 221620.0000 - tp: 383.0000 - Precision: 0.0619 - recall: 0.9185 - val_loss: 0.0401 - val_fn: 9.0000 - val_fp: 663.0000 - val_tn: 56224.0000 - val_tp: 66.0000 - val_Precision: 0.0905 - val_recall: 0.8800\n",
            "Epoch 4/30\n",
            "112/112 - 1s - loss: 1.0511e-06 - fn: 20.0000 - fp: 7219.0000 - tn: 220209.0000 - tp: 397.0000 - Precision: 0.0521 - recall: 0.9520 - val_loss: 0.1453 - val_fn: 7.0000 - val_fp: 2534.0000 - val_tn: 54353.0000 - val_tp: 68.0000 - val_Precision: 0.0261 - val_recall: 0.9067\n",
            "Epoch 5/30\n",
            "112/112 - 1s - loss: 9.1156e-07 - fn: 22.0000 - fp: 6733.0000 - tn: 220695.0000 - tp: 395.0000 - Precision: 0.0554 - recall: 0.9472 - val_loss: 0.0436 - val_fn: 9.0000 - val_fp: 532.0000 - val_tn: 56355.0000 - val_tp: 66.0000 - val_Precision: 0.1104 - val_recall: 0.8800\n",
            "Epoch 6/30\n",
            "112/112 - 1s - loss: 8.4634e-07 - fn: 21.0000 - fp: 7675.0000 - tn: 219753.0000 - tp: 396.0000 - Precision: 0.0491 - recall: 0.9496 - val_loss: 0.0839 - val_fn: 8.0000 - val_fp: 1597.0000 - val_tn: 55290.0000 - val_tp: 67.0000 - val_Precision: 0.0403 - val_recall: 0.8933\n",
            "Epoch 7/30\n",
            "112/112 - 1s - loss: 7.7855e-07 - fn: 17.0000 - fp: 6301.0000 - tn: 221127.0000 - tp: 400.0000 - Precision: 0.0597 - recall: 0.9592 - val_loss: 0.1296 - val_fn: 6.0000 - val_fp: 3295.0000 - val_tn: 53592.0000 - val_tp: 69.0000 - val_Precision: 0.0205 - val_recall: 0.9200\n",
            "Epoch 8/30\n",
            "112/112 - 1s - loss: 6.8277e-07 - fn: 14.0000 - fp: 5937.0000 - tn: 221491.0000 - tp: 403.0000 - Precision: 0.0636 - recall: 0.9664 - val_loss: 0.0613 - val_fn: 8.0000 - val_fp: 1436.0000 - val_tn: 55451.0000 - val_tp: 67.0000 - val_Precision: 0.0446 - val_recall: 0.8933\n",
            "Epoch 9/30\n",
            "112/112 - 1s - loss: 5.8007e-07 - fn: 9.0000 - fp: 5208.0000 - tn: 222220.0000 - tp: 408.0000 - Precision: 0.0726 - recall: 0.9784 - val_loss: 0.0339 - val_fn: 9.0000 - val_fp: 795.0000 - val_tn: 56092.0000 - val_tp: 66.0000 - val_Precision: 0.0767 - val_recall: 0.8800\n",
            "Epoch 10/30\n",
            "112/112 - 1s - loss: 7.1031e-07 - fn: 15.0000 - fp: 8429.0000 - tn: 218999.0000 - tp: 402.0000 - Precision: 0.0455 - recall: 0.9640 - val_loss: 0.0304 - val_fn: 10.0000 - val_fp: 648.0000 - val_tn: 56239.0000 - val_tp: 65.0000 - val_Precision: 0.0912 - val_recall: 0.8667\n",
            "Epoch 11/30\n",
            "112/112 - 1s - loss: 4.7997e-07 - fn: 11.0000 - fp: 5457.0000 - tn: 221971.0000 - tp: 406.0000 - Precision: 0.0692 - recall: 0.9736 - val_loss: 0.0436 - val_fn: 10.0000 - val_fp: 1087.0000 - val_tn: 55800.0000 - val_tp: 65.0000 - val_Precision: 0.0564 - val_recall: 0.8667\n",
            "Epoch 12/30\n",
            "112/112 - 1s - loss: 5.5769e-07 - fn: 13.0000 - fp: 6025.0000 - tn: 221403.0000 - tp: 404.0000 - Precision: 0.0628 - recall: 0.9688 - val_loss: 0.0431 - val_fn: 10.0000 - val_fp: 997.0000 - val_tn: 55890.0000 - val_tp: 65.0000 - val_Precision: 0.0612 - val_recall: 0.8667\n",
            "Epoch 13/30\n",
            "112/112 - 1s - loss: 4.2587e-07 - fn: 8.0000 - fp: 5081.0000 - tn: 222347.0000 - tp: 409.0000 - Precision: 0.0745 - recall: 0.9808 - val_loss: 0.0159 - val_fn: 12.0000 - val_fp: 347.0000 - val_tn: 56540.0000 - val_tp: 63.0000 - val_Precision: 0.1537 - val_recall: 0.8400\n",
            "Epoch 14/30\n",
            "112/112 - 1s - loss: 5.4446e-07 - fn: 9.0000 - fp: 5469.0000 - tn: 221959.0000 - tp: 408.0000 - Precision: 0.0694 - recall: 0.9784 - val_loss: 0.0405 - val_fn: 8.0000 - val_fp: 1301.0000 - val_tn: 55586.0000 - val_tp: 67.0000 - val_Precision: 0.0490 - val_recall: 0.8933\n",
            "Epoch 15/30\n",
            "112/112 - 1s - loss: 8.7201e-07 - fn: 15.0000 - fp: 9979.0000 - tn: 217449.0000 - tp: 402.0000 - Precision: 0.0387 - recall: 0.9640 - val_loss: 0.0611 - val_fn: 8.0000 - val_fp: 953.0000 - val_tn: 55934.0000 - val_tp: 67.0000 - val_Precision: 0.0657 - val_recall: 0.8933\n",
            "Epoch 16/30\n",
            "112/112 - 1s - loss: 8.1485e-07 - fn: 11.0000 - fp: 6936.0000 - tn: 220492.0000 - tp: 406.0000 - Precision: 0.0553 - recall: 0.9736 - val_loss: 0.2067 - val_fn: 7.0000 - val_fp: 2074.0000 - val_tn: 54813.0000 - val_tp: 68.0000 - val_Precision: 0.0317 - val_recall: 0.9067\n",
            "Epoch 17/30\n",
            "112/112 - 1s - loss: 1.8376e-06 - fn: 14.0000 - fp: 7818.0000 - tn: 219610.0000 - tp: 403.0000 - Precision: 0.0490 - recall: 0.9664 - val_loss: 0.0137 - val_fn: 12.0000 - val_fp: 182.0000 - val_tn: 56705.0000 - val_tp: 63.0000 - val_Precision: 0.2571 - val_recall: 0.8400\n",
            "Epoch 18/30\n",
            "112/112 - 1s - loss: 7.0596e-07 - fn: 13.0000 - fp: 6580.0000 - tn: 220848.0000 - tp: 404.0000 - Precision: 0.0578 - recall: 0.9688 - val_loss: 0.0865 - val_fn: 6.0000 - val_fp: 1830.0000 - val_tn: 55057.0000 - val_tp: 69.0000 - val_Precision: 0.0363 - val_recall: 0.9200\n",
            "Epoch 19/30\n",
            "112/112 - 1s - loss: 5.2555e-07 - fn: 6.0000 - fp: 5123.0000 - tn: 222305.0000 - tp: 411.0000 - Precision: 0.0743 - recall: 0.9856 - val_loss: 0.0747 - val_fn: 6.0000 - val_fp: 2008.0000 - val_tn: 54879.0000 - val_tp: 69.0000 - val_Precision: 0.0332 - val_recall: 0.9200\n",
            "Epoch 20/30\n",
            "112/112 - 1s - loss: 3.2037e-07 - fn: 5.0000 - fp: 3654.0000 - tn: 223774.0000 - tp: 412.0000 - Precision: 0.1013 - recall: 0.9880 - val_loss: 0.0261 - val_fn: 10.0000 - val_fp: 608.0000 - val_tn: 56279.0000 - val_tp: 65.0000 - val_Precision: 0.0966 - val_recall: 0.8667\n",
            "Epoch 21/30\n",
            "112/112 - 1s - loss: 5.7154e-07 - fn: 6.0000 - fp: 5860.0000 - tn: 221568.0000 - tp: 411.0000 - Precision: 0.0655 - recall: 0.9856 - val_loss: 0.0191 - val_fn: 9.0000 - val_fp: 375.0000 - val_tn: 56512.0000 - val_tp: 66.0000 - val_Precision: 0.1497 - val_recall: 0.8800\n",
            "Epoch 22/30\n",
            "112/112 - 1s - loss: 5.0708e-07 - fn: 8.0000 - fp: 5021.0000 - tn: 222407.0000 - tp: 409.0000 - Precision: 0.0753 - recall: 0.9808 - val_loss: 0.0179 - val_fn: 10.0000 - val_fp: 306.0000 - val_tn: 56581.0000 - val_tp: 65.0000 - val_Precision: 0.1752 - val_recall: 0.8667\n",
            "Epoch 23/30\n",
            "112/112 - 1s - loss: 3.8192e-07 - fn: 4.0000 - fp: 4553.0000 - tn: 222875.0000 - tp: 413.0000 - Precision: 0.0832 - recall: 0.9904 - val_loss: 0.0190 - val_fn: 10.0000 - val_fp: 425.0000 - val_tn: 56462.0000 - val_tp: 65.0000 - val_Precision: 0.1327 - val_recall: 0.8667\n",
            "Epoch 24/30\n",
            "112/112 - 1s - loss: 2.6319e-07 - fn: 2.0000 - fp: 3180.0000 - tn: 224248.0000 - tp: 415.0000 - Precision: 0.1154 - recall: 0.9952 - val_loss: 0.0122 - val_fn: 10.0000 - val_fp: 223.0000 - val_tn: 56664.0000 - val_tp: 65.0000 - val_Precision: 0.2257 - val_recall: 0.8667\n",
            "Epoch 25/30\n",
            "112/112 - 1s - loss: 3.9954e-07 - fn: 4.0000 - fp: 3891.0000 - tn: 223537.0000 - tp: 413.0000 - Precision: 0.0960 - recall: 0.9904 - val_loss: 0.0729 - val_fn: 7.0000 - val_fp: 2576.0000 - val_tn: 54311.0000 - val_tp: 68.0000 - val_Precision: 0.0257 - val_recall: 0.9067\n",
            "Epoch 26/30\n",
            "112/112 - 1s - loss: 3.8962e-07 - fn: 5.0000 - fp: 4449.0000 - tn: 222979.0000 - tp: 412.0000 - Precision: 0.0848 - recall: 0.9880 - val_loss: 0.0568 - val_fn: 8.0000 - val_fp: 1537.0000 - val_tn: 55350.0000 - val_tp: 67.0000 - val_Precision: 0.0418 - val_recall: 0.8933\n",
            "Epoch 27/30\n",
            "112/112 - 1s - loss: 2.5900e-07 - fn: 0.0000e+00 - fp: 3256.0000 - tn: 224172.0000 - tp: 417.0000 - Precision: 0.1135 - recall: 1.0000 - val_loss: 0.0190 - val_fn: 10.0000 - val_fp: 333.0000 - val_tn: 56554.0000 - val_tp: 65.0000 - val_Precision: 0.1633 - val_recall: 0.8667\n",
            "Epoch 28/30\n",
            "112/112 - 1s - loss: 2.2476e-07 - fn: 3.0000 - fp: 2480.0000 - tn: 224948.0000 - tp: 414.0000 - Precision: 0.1431 - recall: 0.9928 - val_loss: 0.0390 - val_fn: 10.0000 - val_fp: 1119.0000 - val_tn: 55768.0000 - val_tp: 65.0000 - val_Precision: 0.0549 - val_recall: 0.8667\n",
            "Epoch 29/30\n",
            "112/112 - 1s - loss: 2.1058e-07 - fn: 2.0000 - fp: 2384.0000 - tn: 225044.0000 - tp: 415.0000 - Precision: 0.1483 - recall: 0.9952 - val_loss: 0.0184 - val_fn: 9.0000 - val_fp: 333.0000 - val_tn: 56554.0000 - val_tp: 66.0000 - val_Precision: 0.1654 - val_recall: 0.8800\n",
            "Epoch 30/30\n",
            "112/112 - 1s - loss: 1.4530e-07 - fn: 2.0000 - fp: 1608.0000 - tn: 225820.0000 - tp: 415.0000 - Precision: 0.2051 - recall: 0.9952 - val_loss: 0.0657 - val_fn: 9.0000 - val_fp: 884.0000 - val_tn: 56003.0000 - val_tp: 66.0000 - val_Precision: 0.0695 - val_recall: 0.8800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd926219b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozoFu81iKcT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8632bf6-53e7-4617-bd2e-2f87e183d87d"
      },
      "source": [
        "loss, fn,fp,tn,tp, precision, recall = model.evaluate(x_test,y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1781/1781 [==============================] - 7s 4ms/step - loss: 0.0657 - fn: 9.0000 - fp: 884.0000 - tn: 56003.0000 - tp: 66.0000 - Precision: 0.0695 - recall: 0.8800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBnRbHRFLEXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecddc4a-137a-4a88-875d-9db3b941ddcd"
      },
      "source": [
        "print('Total correct fraud cases found:', int(tp),' out of ',int(tp+fn), ' cases of fraud' )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total correct fraud cases found: 66  out of  75  cases of fraud\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXCKPJw6Oekb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddddb6c4-14f4-41e8-c740-f7339ee8dbc4"
      },
      "source": [
        "print('Total of incorrect fraud cases found:', int(fp),' out of ',int(fp+tn), ' good transactions' )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total of incorrect fraud cases found: 884  out of  56887  good transactions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij-rmfJZO9sN"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyUkax1-UBGB"
      },
      "source": [
        "72/75 3060 30 epoch Company 2.0  \n",
        "68/75 796 30 epoch Company 1.5  \n",
        "68/75 934 30 epoch Company 1.7  \n",
        "65/75 175 30 epoch Company 1.0  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKrJdsvrUj0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cb4141-421a-426a-a589-0311507b6853"
      },
      "source": [
        "ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creditcard.csv              fraud_model_at_epoch_21.h5\n",
            "creditcard.csv.1            fraud_model_at_epoch_22.h5\n",
            "creditcard.csv.2            fraud_model_at_epoch_23.h5\n",
            "creditcard.csv.3            fraud_model_at_epoch_24.h5\n",
            "creditcard.csv.4            fraud_model_at_epoch_25.h5\n",
            "creditcard.csv.5            fraud_model_at_epoch_26.h5\n",
            "creditcard.csv.6            fraud_model_at_epoch_27.h5\n",
            "creditcard.csv.7            fraud_model_at_epoch_28.h5\n",
            "fraud_model_at_epoch_10.h5  fraud_model_at_epoch_29.h5\n",
            "fraud_model_at_epoch_11.h5  fraud_model_at_epoch_2.h5\n",
            "fraud_model_at_epoch_12.h5  fraud_model_at_epoch_30.h5\n",
            "fraud_model_at_epoch_13.h5  fraud_model_at_epoch_3.h5\n",
            "fraud_model_at_epoch_14.h5  fraud_model_at_epoch_4.h5\n",
            "fraud_model_at_epoch_15.h5  fraud_model_at_epoch_5.h5\n",
            "fraud_model_at_epoch_16.h5  fraud_model_at_epoch_6.h5\n",
            "fraud_model_at_epoch_17.h5  fraud_model_at_epoch_7.h5\n",
            "fraud_model_at_epoch_18.h5  fraud_model_at_epoch_8.h5\n",
            "fraud_model_at_epoch_19.h5  fraud_model_at_epoch_9.h5\n",
            "fraud_model_at_epoch_1.h5   \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "fraud_model_at_epoch_20.h5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}